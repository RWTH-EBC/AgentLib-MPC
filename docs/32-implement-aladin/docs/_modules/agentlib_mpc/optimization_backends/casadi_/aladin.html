

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>agentlib_mpc.optimization_backends.casadi_.aladin &mdash; agentlib_mpc 0.6.6 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/autodoc_pydantic.css" />

  
      <script src="../../../../_static/jquery.js"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
      <script src="../../../../_static/doctools.js"></script>
      <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            agentlib_mpc
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../PackageReference.html">Package Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">agentlib_mpc</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
          <li class="breadcrumb-item"><a href="../../optimization_backends.html">agentlib_mpc.optimization_backends</a></li>
      <li class="breadcrumb-item active">agentlib_mpc.optimization_backends.casadi_.aladin</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for agentlib_mpc.optimization_backends.casadi_.aladin</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">casadi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ca</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pydantic</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.data_structures.admm_datatypes</span><span class="w"> </span><span class="kn">import</span> <span class="n">VariableReference</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.data_structures.casadi_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DiscretizationMethod</span><span class="p">,</span>
    <span class="n">GUESS_PREFIX</span><span class="p">,</span>
    <span class="n">MPCInputs</span><span class="p">,</span>
    <span class="n">CasadiDiscretizationOptions</span><span class="p">,</span>
    <span class="n">SolverFactory</span><span class="p">,</span>
    <span class="n">OptParMXContainer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.data_structures.mpc_datamodels</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPCVariable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.models.casadi_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">CasadiParameter</span><span class="p">,</span> <span class="n">CasadiInput</span><span class="p">,</span> <span class="n">CasadiModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.modules.dmpc.aladin</span><span class="w"> </span><span class="kn">import</span> <span class="n">aladin_datatypes</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.optimization_backends.casadi_.admm</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">CasADiADMMBackend</span><span class="p">,</span>
    <span class="n">ADMMCollocation</span><span class="p">,</span>
    <span class="n">ADMMMultipleShooting</span><span class="p">,</span>
    <span class="n">CasadiADMMSystem</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.optimization_backends.casadi_.basic</span><span class="w"> </span><span class="kn">import</span> <span class="n">DirectCollocation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.optimization_backends.casadi_.core.VariableGroup</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">OptimizationVariable</span><span class="p">,</span>
    <span class="n">OptimizationParameter</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.optimization_backends.casadi_.core.casadi_backend</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">CasadiBackendConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.optimization_backends.casadi_.core.discretization</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Discretization</span><span class="p">,</span>
    <span class="n">Results</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.optimization_backends.casadi_.full</span><span class="w"> </span><span class="kn">import</span> <span class="n">FullSystem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentlib_mpc.utils.plotting.mpc_debugging.aladin_debugging</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">launch_visualization_app</span><span class="p">,</span>
    <span class="n">_prepare_visualization_data</span><span class="p">,</span>
<span class="p">)</span>


<div class="viewcode-block" id="CasadiALADINSystem"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.CasadiALADINSystem">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">CasadiALADINSystem</span><span class="p">(</span><span class="n">FullSystem</span><span class="p">):</span>
    <span class="n">local_couplings</span><span class="p">:</span> <span class="n">OptimizationVariable</span>
    <span class="n">multipliers</span><span class="p">:</span> <span class="n">OptimizationParameter</span>
    <span class="n">penalty_factor</span><span class="p">:</span> <span class="n">OptimizationParameter</span>

<div class="viewcode-block" id="CasadiALADINSystem.initialize"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.CasadiALADINSystem.initialize">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">CasadiModel</span><span class="p">,</span> <span class="n">var_ref</span><span class="p">:</span> <span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">VariableReference</span>
    <span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">var_ref</span><span class="o">=</span><span class="n">var_ref</span><span class="p">)</span>

        <span class="n">coup_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">var_ref</span><span class="o">.</span><span class="n">couplings</span><span class="p">]</span>
        <span class="n">pure_outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">coup_names</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">OptimizationVariable</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span>
            <span class="n">denotation</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span>
            <span class="n">variables</span><span class="o">=</span><span class="n">pure_outs</span><span class="p">,</span>
            <span class="n">ref_list</span><span class="o">=</span><span class="n">var_ref</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">local_couplings</span> <span class="o">=</span> <span class="n">OptimizationVariable</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span>
            <span class="n">denotation</span><span class="o">=</span><span class="s2">&quot;local_couplings&quot;</span><span class="p">,</span>
            <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">coup_names</span><span class="p">],</span>
            <span class="n">ref_list</span><span class="o">=</span><span class="n">coup_names</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">multipliers</span> <span class="o">=</span> <span class="p">[</span><span class="n">coup</span><span class="o">.</span><span class="n">multiplier</span> <span class="k">for</span> <span class="n">coup</span> <span class="ow">in</span> <span class="n">var_ref</span><span class="o">.</span><span class="n">couplings</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multipliers</span> <span class="o">=</span> <span class="n">OptimizationParameter</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span>
            <span class="n">denotation</span><span class="o">=</span><span class="s2">&quot;multipliers&quot;</span><span class="p">,</span>
            <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="n">CasadiInput</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">coup</span><span class="p">)</span> <span class="k">for</span> <span class="n">coup</span> <span class="ow">in</span> <span class="n">multipliers</span><span class="p">],</span>
            <span class="n">ref_list</span><span class="o">=</span><span class="n">multipliers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span> <span class="o">=</span> <span class="n">OptimizationParameter</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span>
            <span class="n">denotation</span><span class="o">=</span><span class="s2">&quot;rho&quot;</span><span class="p">,</span>
            <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="n">CasadiParameter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">LOCAL_PENALTY_FACTOR</span><span class="p">)],</span>
            <span class="n">ref_list</span><span class="o">=</span><span class="p">[</span><span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">LOCAL_PENALTY_FACTOR</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># add aladin terms to objective function</span>
        <span class="n">objective</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">var_ref</span><span class="o">.</span><span class="n">couplings</span><span class="p">)):</span>
            <span class="n">local_couplings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_couplings</span><span class="o">.</span><span class="n">full_symbolic</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">multiplier</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multipliers</span><span class="o">.</span><span class="n">full_symbolic</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">objective</span> <span class="o">+=</span> <span class="n">multiplier</span> <span class="o">*</span> <span class="n">local_couplings</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cost_function</span> <span class="o">+=</span> <span class="n">objective</span></div></div>


<div class="viewcode-block" id="ALADINCasadiDiscretizationOptions"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINCasadiDiscretizationOptions">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ALADINCasadiDiscretizationOptions</span><span class="p">(</span><span class="n">CasadiDiscretizationOptions</span><span class="p">):</span>
    <span class="n">regularization_parameter</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span>
    <span class="n">activation_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span></div>


<div class="viewcode-block" id="ALADINDiscretization"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINDiscretization">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ALADINDiscretization</span><span class="p">(</span><span class="n">Discretization</span><span class="p">):</span>
    <span class="n">options</span><span class="p">:</span> <span class="n">ALADINCasadiDiscretizationOptions</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">options</span><span class="p">:</span> <span class="n">ALADINCasadiDiscretizationOptions</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sensitivities_result</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_variable</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sensitivities_func</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>

<div class="viewcode-block" id="ALADINDiscretization.get_aladin_registration"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINDiscretization.get_aladin_registration">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_aladin_registration</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">mpc_inputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ca</span><span class="o">.</span><span class="n">DM</span><span class="p">],</span> <span class="n">var_ref</span><span class="p">:</span> <span class="n">VariableReference</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
        <span class="c1"># answer = ald.RegistrationA2C(</span>
        <span class="c1">#     coup_vars=...,</span>
        <span class="c1">#     local_solution=...,</span>
        <span class="c1"># )</span>
        <span class="n">guesses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_determine_initial_guess</span><span class="p">(</span><span class="n">mpc_inputs</span><span class="p">)</span>
        <span class="n">mpc_inputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">guesses</span><span class="p">)</span>
        <span class="n">nlp_inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ca</span><span class="o">.</span><span class="n">DM</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpc_inputs_to_nlp_inputs</span><span class="p">(</span><span class="o">**</span><span class="n">mpc_inputs</span><span class="p">)</span>

        <span class="n">local_solution</span> <span class="o">=</span> <span class="n">nlp_inputs</span><span class="p">[</span><span class="s2">&quot;x0&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
        <span class="n">opt_var_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">local_solution</span><span class="p">)</span>
        <span class="n">mpc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_outputs_to_mpc_outputs</span><span class="p">(</span>
            <span class="n">vars_at_optimum</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">opt_var_length</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_solution</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">mpc_inputs</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">mpc_output</span><span class="p">,</span>
            <span class="n">objective_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">coup_vars</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">var_ref</span><span class="o">.</span><span class="n">couplings</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">local_solution</span><span class="p">,</span> <span class="n">coup_vars</span></div>

<div class="viewcode-block" id="ALADINDiscretization.shift_opt_var"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINDiscretization.shift_opt_var">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shift_opt_var</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
        <span class="n">current_optimum</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sa">f</span><span class="s2">&quot;guess_</span><span class="si">{</span><span class="n">den</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">var</span><span class="o">.</span><span class="n">opt</span> <span class="k">for</span> <span class="n">den</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mpc_opt_vars</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>

        <span class="c1"># if this is the first step, just return none</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">current_optimum</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">den</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mpc_opt_vars</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">den</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;guess_</span><span class="si">{</span><span class="n">den</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">var</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

                <span class="c1"># skip if there are no variables of that type</span>
                <span class="k">continue</span>
            <span class="n">shift_by</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">grid</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">prediction_horizon</span><span class="p">)</span>
            <span class="c1"># have to use the key guess_... here, as the _mpc_inputs_to_nlp_inputs</span>
            <span class="c1"># original implementation uses that, and we want to use that function</span>
            <span class="n">current_optimum</span><span class="p">[</span><span class="n">den</span><span class="p">]</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">horzcat</span><span class="p">(</span>  <span class="c1"># have to use guess here as</span>
                <span class="n">current_optimum</span><span class="p">[</span><span class="n">den</span><span class="p">][:,</span> <span class="n">shift_by</span><span class="p">:],</span> <span class="n">current_optimum</span><span class="p">[</span><span class="n">den</span><span class="p">][:,</span> <span class="o">-</span><span class="n">shift_by</span><span class="p">:]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpc_inputs_to_nlp_inputs</span><span class="p">(</span><span class="o">**</span><span class="n">current_optimum</span><span class="p">)[</span><span class="s2">&quot;x0&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ALADINDiscretization.solve"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINDiscretization.solve">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mpc_inputs</span><span class="p">:</span> <span class="n">MPCInputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Results</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Solves the discretized trajectory optimization problem.</span>
<span class="sd">        ... (rest of docstring) ...</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># todo get these from coordinator</span>
        <span class="n">regularization_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">regularization_parameter</span>
        <span class="n">activation_margin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">activation_margin</span>

        <span class="c1"># collect and format inputs</span>
        <span class="n">guesses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_determine_initial_guess</span><span class="p">(</span><span class="n">mpc_inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_variable</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Handle case where global_variable might not be set yet (e.g., first iteration)</span>
            <span class="c1"># You might need to initialize it to zeros or based on guess</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;ALADINDiscretization.global_variable is None. Using zeros.&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Determine expected shape - requires knowing the flattened opt_vars size</span>
            <span class="c1"># This is tricky before create_nlp_in_out_mapping fully defines self.opt_vars</span>
            <span class="c1"># For now, let&#39;s assume it might fail gracefully later or needs initialization logic</span>
            <span class="c1"># A placeholder:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;opt_vars&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">expected_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="o">.</span><span class="n">shape</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">global_variable</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">DM</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">expected_shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Cannot determine shape yet, visualization might fail if global_variable is needed later</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot determine shape for global_variable initialization.&quot;</span>
                <span class="p">)</span>
                <span class="c1"># Or raise an error if it&#39;s essential here</span>
                <span class="c1"># raise ValueError(&quot;global_variable must be set before calling solve&quot;)</span>
                <span class="k">pass</span>  <span class="c1"># Allow to proceed, hoping it&#39;s set elsewhere or not strictly needed yet</span>

        <span class="c1"># Ensure global_variable is set if required by the mapping</span>
        <span class="k">if</span> <span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">PRESCRIBED</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpc_inputs_to_nlp_inputs</span><span class="o">.</span><span class="n">name_in</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_variable</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">PRESCRIBED</span><span class="si">}</span><span class="s2"> is required by NLP mapping but global_variable is None.&quot;</span>
                <span class="p">)</span>
            <span class="n">mpc_inputs</span><span class="p">[</span><span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">PRESCRIBED</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_variable</span>

        <span class="n">mpc_inputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">guesses</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">nlp_inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ca</span><span class="o">.</span><span class="n">DM</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpc_inputs_to_nlp_inputs</span><span class="p">(</span><span class="o">**</span><span class="n">mpc_inputs</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during _mpc_inputs_to_nlp_inputs mapping: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Available mpc_inputs keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">mpc_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected nlp_inputs keys: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_mpc_inputs_to_nlp_inputs</span><span class="o">.</span><span class="n">name_in</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="c1"># You might want to inspect the shapes of mpc_inputs here</span>
            <span class="k">raise</span>

        <span class="c1"># perform optimization</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">nlp_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">(</span><span class="o">**</span><span class="n">nlp_inputs</span><span class="p">)</span>
            <span class="n">debug_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during NLP optimization: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># Optionally log nlp_inputs for debugging</span>
            <span class="c1"># logging.error(f&quot;NLP Inputs: {nlp_inputs}&quot;)</span>
            <span class="k">raise</span>

        <span class="c1"># --- Post-processing and Sensitivity ---</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Use optimal solution x and parameters p to get constraint values</span>
            <span class="n">constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_constraints</span><span class="p">(</span>
                <span class="n">opt_vars</span><span class="o">=</span><span class="n">nlp_output</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">opt_pars</span><span class="o">=</span><span class="n">nlp_inputs</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">]</span>
            <span class="p">)[</span><span class="s2">&quot;constraints&quot;</span><span class="p">]</span>
            <span class="n">constraints</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># Ensure numpy vector</span>

            <span class="n">active_constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_active_constraints</span><span class="p">(</span>
                <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
                <span class="n">lb</span><span class="o">=</span><span class="n">nlp_inputs</span><span class="p">[</span><span class="s2">&quot;lbg&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                <span class="n">ub</span><span class="o">=</span><span class="n">nlp_inputs</span><span class="p">[</span><span class="s2">&quot;ubg&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                <span class="n">act_margin</span><span class="o">=</span><span class="n">activation_margin</span><span class="p">,</span>
            <span class="p">)</span>  <span class="c1"># Should return flat bool numpy array</span>

            <span class="c1"># --- Get Sensitivities ---</span>
            <span class="n">sensitivities_result</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">debug_sensitivities</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Store intermediate debug values here</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sensitivities_func</span><span class="p">:</span>
                <span class="c1"># Ensure lam_g is correctly shaped and zeroed for inactive constraints</span>
                <span class="n">lam_g_full</span> <span class="o">=</span> <span class="n">nlp_output</span><span class="p">[</span><span class="s2">&quot;lam_g&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lam_g_full</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_constraints</span><span class="p">):</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Mismatch length lam_g (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lam_g_full</span><span class="p">)</span><span class="si">}</span><span class="s2">) vs active_constraints (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">active_constraints</span><span class="p">)</span><span class="si">}</span><span class="s2">). Check NLP solver output.&quot;</span>
                    <span class="p">)</span>
                    <span class="c1"># Attempt to resize/pad if possible, or handle error</span>
                    <span class="c1"># For now, proceed cautiously</span>
                    <span class="n">min_len_sens</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lam_g_full</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_constraints</span><span class="p">))</span>
                    <span class="n">lam_g_active</span> <span class="o">=</span> <span class="n">lam_g_full</span><span class="p">[:</span><span class="n">min_len_sens</span><span class="p">]</span>
                    <span class="n">active_mask_sens</span> <span class="o">=</span> <span class="n">active_constraints</span><span class="p">[:</span><span class="n">min_len_sens</span><span class="p">]</span>
                    <span class="n">lam_g_active</span><span class="p">[</span><span class="o">~</span><span class="n">active_mask_sens</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">lam_g_active</span> <span class="o">=</span> <span class="n">lam_g_full</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                    <span class="n">lam_g_active</span><span class="p">[</span><span class="o">~</span><span class="n">active_constraints</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Call sensitivity function</span>
                    <span class="n">sens_result_raw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sensitivities_func</span><span class="p">(</span>
                        <span class="n">opt_vars</span><span class="o">=</span><span class="n">nlp_output</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
                        <span class="n">opt_pars</span><span class="o">=</span><span class="n">nlp_inputs</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">],</span>
                        <span class="n">local_constraint_multipliers</span><span class="o">=</span><span class="n">ca</span><span class="o">.</span><span class="n">DM</span><span class="p">(</span><span class="n">lam_g_active</span><span class="p">),</span>
                        <span class="c1"># Pass potentially modified lam_g</span>
                    <span class="p">)</span>

                    <span class="c1"># Store results, converting to numpy where appropriate</span>
                    <span class="n">sensitivities_result</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="n">ca</span><span class="o">.</span><span class="n">DM</span><span class="p">,</span> <span class="n">ca</span><span class="o">.</span><span class="n">MX</span><span class="p">))</span> <span class="k">else</span> <span class="n">v</span>
                        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sens_result_raw</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>

                    <span class="c1"># --- Regularization and Debug Info ---</span>
                    <span class="k">if</span> <span class="s2">&quot;H&quot;</span> <span class="ow">in</span> <span class="n">sensitivities_result</span> <span class="ow">and</span> <span class="s2">&quot;J&quot;</span> <span class="ow">in</span> <span class="n">sensitivities_result</span><span class="p">:</span>
                        <span class="c1"># Store original H for comparison</span>
                        <span class="n">debug_sensitivities</span><span class="p">[</span><span class="s2">&quot;H_original&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitivities_result</span><span class="p">[</span>
                            <span class="s2">&quot;H&quot;</span>
                        <span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

                        <span class="c1"># Filter Jacobian J to only include active constraints IF NEEDED</span>
                        <span class="c1"># The current implementation seems to calculate J based on *all* constraints</span>
                        <span class="c1"># and relies on lam_g being zero for inactive ones.</span>
                        <span class="c1"># If J *should* only contain active rows, filter here:</span>
                        <span class="c1"># sensitivities_result[&quot;J&quot;] = sensitivities_result[&quot;J&quot;][active_constraints, :] # Filter rows</span>

                        <span class="c1"># Regularize Hessian</span>
                        <span class="n">sensitivities_result</span><span class="p">[</span><span class="s2">&quot;H&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">regularize_h</span><span class="p">(</span>
                            <span class="n">sensitivities_result</span><span class="p">[</span><span class="s2">&quot;H&quot;</span><span class="p">],</span> <span class="n">regularization_parameter</span>
                        <span class="p">)</span>

                        <span class="c1"># Store full Jacobian if calculated separately for debugging</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                            <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_full_constraint_jacobian_func&quot;</span>
                        <span class="p">):</span>  <span class="c1"># Example if you had such a func</span>
                            <span class="n">full_jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_full_constraint_jacobian_func</span><span class="p">(</span>
                                <span class="n">opt_vars</span><span class="o">=</span><span class="n">nlp_output</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">opt_pars</span><span class="o">=</span><span class="n">nlp_inputs</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">]</span>
                            <span class="p">)</span>
                            <span class="n">debug_sensitivities</span><span class="p">[</span><span class="s2">&quot;jacobian_all&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">full_jac</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
                        <span class="k">elif</span> <span class="p">(</span>
                            <span class="s2">&quot;jacobian_all&quot;</span> <span class="ow">in</span> <span class="n">debug_sensitivities</span>
                        <span class="p">):</span>  <span class="c1"># If already stored earlier</span>
                            <span class="k">pass</span>  <span class="c1"># Already have it</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Fallback: Use the J from sensitivities if it represents all constraints</span>
                            <span class="c1"># This depends heavily on how _sensitivities_func is defined!</span>
                            <span class="c1"># Assuming J from sens_func *is* the full Jacobian before filtering:</span>
                            <span class="n">debug_sensitivities</span><span class="p">[</span><span class="s2">&quot;jacobian_all&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitivities_result</span><span class="p">[</span>
                                <span class="s2">&quot;J&quot;</span>
                            <span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># Or load from debug_jacobian if stored earlier</span>
                            <span class="c1"># **IMPORTANT**: Adjust this logic based on your actual implementation</span>
                            <span class="c1"># If J in sensitivities_result is *already* filtered, you need another way</span>
                            <span class="c1"># to get the full Jacobian for the &#39;jacobian_all&#39; visualization.</span>

                        <span class="c1"># Store other debug values if calculated</span>
                        <span class="c1"># debug_sensitivities[&#39;gradient_lambda_zero&#39;] = ...</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="s2">&quot;Hessian (H) or Jacobian (J) missing from sensitivity results.&quot;</span>
                        <span class="p">)</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">raise</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during sensitivity calculation: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="c1"># Optionally log inputs to sensitivity function</span>
                    <span class="c1"># logging.error(f&quot;Sensitivity Inputs: opt_vars={nlp_output[&#39;x&#39;]}, opt_pars={nlp_inputs[&#39;p&#39;]}, lam_g={lam_g_active}&quot;)</span>
                    <span class="n">sensitivities_result</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="kc">None</span>  <span class="c1"># Ensure it&#39;s None if calculation failed</span>
                    <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;_sensitivities_func is not defined. Cannot calculate sensitivities.&quot;</span>
                <span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span>

            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Error during post-processing or sensitivity calculation: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="c1"># Ensure results are handled gracefully even if errors occurred</span>
            <span class="n">sensitivities_result</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">debug_sensitivities</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="c1"># Depending on severity, you might want to re-raise or return partial results</span>
            <span class="c1"># For debugging, let&#39;s try to continue to visualization if possible</span>

        <span class="c1"># --- Prepare Data for Visualization ---</span>
        <span class="c1"># Ensure all required components exist before preparing data</span>
        <span class="n">vis_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Pass necessary components to the preparation function</span>
            <span class="n">vis_data</span> <span class="o">=</span> <span class="n">_prepare_visualization_data</span><span class="p">(</span>
                <span class="n">discretization_obj</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">nlp_inputs</span><span class="o">=</span><span class="n">nlp_inputs</span><span class="p">,</span>
                <span class="n">nlp_output</span><span class="o">=</span><span class="n">nlp_output</span><span class="p">,</span>
                <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>  <span class="c1"># Should be flat numpy array now</span>
                <span class="n">active_constraints</span><span class="o">=</span><span class="n">active_constraints</span><span class="p">,</span>
                <span class="c1"># Should be flat bool numpy array</span>
                <span class="n">sensitivities_result</span><span class="o">=</span><span class="n">sensitivities_result</span><span class="p">,</span>
                <span class="c1"># Dict with numpy arrays or None</span>
                <span class="n">debug_sensitivities</span><span class="o">=</span><span class="n">debug_sensitivities</span><span class="p">,</span>  <span class="c1"># Dict with numpy arrays</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error preparing visualization data: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># Log the state of inputs to _prepare_visualization_data if helpful</span>
            <span class="c1"># logging.error(f&quot;Inputs to prep func: nlp_inputs keys={list(nlp_inputs.keys())}, nlp_output keys={list(nlp_output.keys())}, constraints shape={constraints.shape if constraints is not None else &#39;None&#39;}, ...&quot;)</span>

        <span class="c1"># --- Launch Visualization App ---</span>
        <span class="k">if</span> <span class="n">vis_data</span><span class="p">:</span>  <span class="c1"># Only launch if data preparation succeeded</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Launching visualization app...&quot;</span><span class="p">)</span>
                <span class="n">launch_visualization_app</span><span class="p">(</span><span class="n">vis_data</span><span class="p">)</span>  <span class="c1"># Launch in a thread</span>
                <span class="c1"># Optional: Add a small delay or wait mechanism if needed</span>
                <span class="c1"># time.sleep(1)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to launch visualization app: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping visualization launch due to missing data.&quot;</span><span class="p">)</span>

        <span class="c1"># --- Format and Return Solution ---</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">mpc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_outputs_to_mpc_outputs</span><span class="p">(</span>
                <span class="n">vars_at_optimum</span><span class="o">=</span><span class="n">nlp_output</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remember_solution</span><span class="p">(</span><span class="n">mpc_output</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_solution</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">mpc_inputs</span><span class="p">,</span>  <span class="c1"># Pass original mpc_inputs</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">mpc_output</span><span class="p">,</span>
                <span class="n">objective_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">nlp_output</span><span class="p">[</span><span class="s2">&quot;f&quot;</span><span class="p">]),</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error formatting final results: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># Depending on requirements, return None, raise error, or return partial result</span>
            <span class="k">raise</span>  <span class="c1"># Re-raise for now</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_active_constraints</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">constraints</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">lb</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ub</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">act_margin</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a boolean array of constraints that are considered active.&quot;&quot;&quot;</span>
        <span class="c1"># Check if lb and ub have the same shape as constraints</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">lb</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">ub</span><span class="o">.</span><span class="n">shape</span>
        <span class="p">),</span> <span class="s2">&quot;Constraints, lb, and ub must have the same shape&quot;</span>

        <span class="c1"># Create a boolean array to store active constraints</span>
        <span class="n">active_constraints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">constraints</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>

        <span class="c1"># Check equality constraints</span>
        <span class="n">equality_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lb</span> <span class="o">==</span> <span class="n">ub</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">active_constraints</span><span class="p">[</span><span class="n">equality_mask</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Check inequality constraints</span>
        <span class="n">inequality_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lb</span> <span class="o">&lt;</span> <span class="n">ub</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">active_upper</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ub</span> <span class="o">-</span> <span class="n">constraints</span> <span class="o">&lt;</span> <span class="n">act_margin</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">inequality_mask</span>
        <span class="p">)</span>
        <span class="n">active_lower</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">constraints</span> <span class="o">-</span> <span class="n">lb</span> <span class="o">&lt;</span> <span class="n">act_margin</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">inequality_mask</span>
        <span class="p">)</span>
        <span class="n">active_constraints</span><span class="p">[</span><span class="n">active_upper</span> <span class="o">|</span> <span class="n">active_lower</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="n">active_constraints</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<div class="viewcode-block" id="ALADINDiscretization.initialize"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINDiscretization.initialize">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system</span><span class="p">:</span> <span class="n">CasadiALADINSystem</span><span class="p">,</span> <span class="n">solver_factory</span><span class="p">:</span> <span class="n">SolverFactory</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the trajectory optimization problem, creating all symbolic</span>
<span class="sd">        variables of the OCP, the mapping function and the numerical solver.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_system</span> <span class="o">=</span> <span class="n">system</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_discretize</span><span class="p">(</span><span class="n">system</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_finished_discretization</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># self._aladin_modifications(system)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_nlp_in_out_mapping</span><span class="p">(</span><span class="n">system</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_create_solver</span><span class="p">(</span><span class="n">solver_factory</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_aladin_modifications</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system</span><span class="p">:</span> <span class="n">CasadiALADINSystem</span><span class="p">):</span>
        <span class="c1"># inject aladin coupling term</span>
        <span class="n">rho</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">system</span><span class="o">.</span><span class="n">penalty_factor</span><span class="p">)</span>
        <span class="n">optvars</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">)</span>
        <span class="n">global_coupling</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">MX</span><span class="o">.</span><span class="n">sym</span><span class="p">(</span><span class="s2">&quot;global_coupling&quot;</span><span class="p">,</span> <span class="n">optvars</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">par_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mpc_opt_pars</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span>
            <span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">PRESCRIBED</span><span class="p">,</span> <span class="n">OptParMXContainer</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">par_list</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">global_coupling</span><span class="p">)</span>
        <span class="n">coupling_cost</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ca</span><span class="o">.</span><span class="n">norm_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span> <span class="o">-</span> <span class="n">global_coupling</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span> <span class="o">+=</span> <span class="n">coupling_cost</span>

        <span class="c1"># create functions for sensitivities</span>
        <span class="n">objective_gradient</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span><span class="s2">&quot;obj_grad&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span><span class="p">,</span> <span class="n">optvars</span><span class="p">)</span>

        <span class="n">constraint_jacobian</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span><span class="s2">&quot;cons_jac&quot;</span><span class="p">,</span> <span class="p">[])</span>

<div class="viewcode-block" id="ALADINDiscretization.create_nlp_in_out_mapping"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINDiscretization.create_nlp_in_out_mapping">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">create_nlp_in_out_mapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system</span><span class="p">:</span> <span class="n">CasadiALADINSystem</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function creating mapping functions between the MPC variables ordered</span>
<span class="sd">        by type (as defined in `declare_quantities` and the raw input/output</span>
<span class="sd">        vector of the CasADi NLP.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># add penalty parameter</span>
        <span class="n">rho</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">system</span><span class="o">.</span><span class="n">penalty_factor</span><span class="p">)</span>

        <span class="c1"># Concatenate nlp variables to CasADi MX vectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span><span class="p">)</span>
        <span class="n">initial_guess</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_guess</span><span class="p">)</span>
        <span class="n">opt_vars_lb</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars_lb</span><span class="p">)</span>
        <span class="n">opt_vars_ub</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars_ub</span><span class="p">)</span>
        <span class="n">constraints_lb</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints_lb</span><span class="p">)</span>
        <span class="n">constraints_ub</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints_ub</span><span class="p">)</span>

        <span class="c1"># create empty lists to store all nlp inputs and outputs</span>
        <span class="n">mpc_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">aladin_inputs_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">mpc_input_denotations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mpc_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mpc_output_denotations</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Concatenate mpc outputs and their bounds to CasADi MX matrices</span>
        <span class="k">for</span> <span class="n">denotation</span><span class="p">,</span> <span class="n">opt_var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mpc_opt_vars</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># mpc opt vars</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">opt_var</span><span class="o">.</span><span class="n">var</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">horzcat</span><span class="p">(</span><span class="o">*</span><span class="n">var</span><span class="p">)</span>
            <span class="n">mpc_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
            <span class="n">mpc_output_denotations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">denotation</span><span class="p">)</span>

            <span class="c1"># their bounds and guess</span>
            <span class="n">lb</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">horzcat</span><span class="p">(</span><span class="o">*</span><span class="n">opt_var</span><span class="o">.</span><span class="n">lb</span><span class="p">)</span>
            <span class="n">ub</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">horzcat</span><span class="p">(</span><span class="o">*</span><span class="n">opt_var</span><span class="o">.</span><span class="n">ub</span><span class="p">)</span>
            <span class="n">guess</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">horzcat</span><span class="p">(</span><span class="o">*</span><span class="n">opt_var</span><span class="o">.</span><span class="n">guess</span><span class="p">)</span>
            <span class="n">mpc_inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">,</span> <span class="n">guess</span><span class="p">])</span>
            <span class="n">mpc_input_denotations</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;lb_</span><span class="si">{</span><span class="n">denotation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;ub_</span><span class="si">{</span><span class="n">denotation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">GUESS_PREFIX</span> <span class="o">+</span> <span class="n">denotation</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="c1"># Concatenate mpc inputs to CasADi MX matrices</span>
        <span class="k">for</span> <span class="n">denotation</span><span class="p">,</span> <span class="n">opt_par</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mpc_opt_pars</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">opt_par</span><span class="o">.</span><span class="n">var</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">horzcat</span><span class="p">(</span><span class="o">*</span><span class="n">var</span><span class="p">)</span>
            <span class="n">mpc_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
            <span class="n">aladin_inputs_dict</span><span class="p">[</span><span class="n">denotation</span><span class="p">]</span> <span class="o">=</span> <span class="n">var</span>
            <span class="n">mpc_input_denotations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">denotation</span><span class="p">)</span>

        <span class="c1"># inject aladin coupling term</span>
        <span class="n">global_coupling</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">MX</span><span class="o">.</span><span class="n">sym</span><span class="p">(</span><span class="s2">&quot;global_coupling&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">coupling_cost</span> <span class="o">=</span> <span class="p">(</span><span class="n">rho</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">ca</span><span class="o">.</span><span class="n">sumsqr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span> <span class="o">-</span> <span class="n">global_coupling</span><span class="p">)</span>
        <span class="n">original_objective</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span> <span class="o">+=</span> <span class="n">coupling_cost</span>
        <span class="n">mpc_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">global_coupling</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span><span class="p">,</span> <span class="n">global_coupling</span><span class="p">)</span>
        <span class="n">mpc_input_denotations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">PRESCRIBED</span><span class="p">)</span>

        <span class="c1"># nlp inputs</span>
        <span class="n">nlp_inputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span><span class="p">,</span>
            <span class="n">initial_guess</span><span class="p">,</span>
            <span class="n">opt_vars_lb</span><span class="p">,</span>
            <span class="n">opt_vars_ub</span><span class="p">,</span>
            <span class="n">constraints_lb</span><span class="p">,</span>
            <span class="n">constraints_ub</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">nlp_input_denotations</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="s2">&quot;x0&quot;</span><span class="p">,</span> <span class="s2">&quot;lbx&quot;</span><span class="p">,</span> <span class="s2">&quot;ubx&quot;</span><span class="p">,</span> <span class="s2">&quot;lbg&quot;</span><span class="p">,</span> <span class="s2">&quot;ubg&quot;</span><span class="p">]</span>

        <span class="c1"># Mapping function that rearranges the variables for input into the NLP</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mpc_inputs_to_nlp_inputs</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="s2">&quot;mpc_inputs_to_nlp_inputs&quot;</span><span class="p">,</span>
            <span class="n">mpc_inputs</span><span class="p">,</span>
            <span class="n">nlp_inputs</span><span class="p">,</span>
            <span class="n">mpc_input_denotations</span><span class="p">,</span>
            <span class="n">nlp_input_denotations</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Mapping function that rearranges the output of the nlp and sorts</span>
        <span class="c1"># by denotation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_outputs_to_mpc_outputs</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="s2">&quot;nlp_outputs_to_mpc_outputs&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">],</span>
            <span class="n">mpc_outputs</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">&quot;vars_at_optimum&quot;</span><span class="p">],</span>
            <span class="n">mpc_output_denotations</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># create function to extract constraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_constraints</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="s2">&quot;constraints&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span><span class="p">],</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;opt_vars&quot;</span><span class="p">,</span> <span class="s2">&quot;opt_pars&quot;</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;constraints&quot;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># create functions for sensitivities</span>
        <span class="c1"># todo in some papers, gradient here includes dot product of jacobian error times lam_g</span>
        <span class="n">objective_gradient</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">original_objective</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">)</span>
        <span class="n">aladin_inputs_dict</span><span class="p">[</span><span class="s2">&quot;multipliers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">MX</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="o">*</span><span class="n">aladin_inputs_dict</span><span class="p">[</span><span class="s2">&quot;multipliers&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="p">)</span>
        <span class="n">substituted_opt_pars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpc_inputs_to_nlp_inputs</span><span class="p">(</span><span class="o">**</span><span class="n">aladin_inputs_dict</span><span class="p">)[</span><span class="s2">&quot;p&quot;</span><span class="p">]</span>
        <span class="n">objective_gradient_function</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="s2">&quot;obj_grad&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span><span class="p">],</span> <span class="p">[</span><span class="n">objective_gradient</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">objective_gradient_lambda_zero</span> <span class="o">=</span> <span class="n">objective_gradient_function</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span> <span class="n">substituted_opt_pars</span>
        <span class="p">)</span>
        <span class="n">constraint_jacobian</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">jacobian</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">)</span>
        <span class="c1"># todo somehow find out how to check for inactive inequality constraints</span>
        <span class="n">constraint_multipliers</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">MX</span><span class="o">.</span><span class="n">sym</span><span class="p">(</span><span class="s2">&quot;cons_mult&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">hessian</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span>
            <span class="n">original_objective</span> <span class="o">+</span> <span class="n">constraint_multipliers</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># todo find out, if the box constraints should be included, or if we use 1s there, and why it is ones. Box constraints are not included in Engelmann implementation, but why</span>
        <span class="n">hessian_function</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="s2">&quot;hessian_func&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span><span class="p">,</span> <span class="n">constraint_multipliers</span><span class="p">],</span>
            <span class="p">[</span><span class="n">hessian</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">hessian_lambda_zero</span> <span class="o">=</span> <span class="n">hessian_function</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span> <span class="n">substituted_opt_pars</span><span class="p">,</span> <span class="n">constraint_multipliers</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sensitivities_func</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="s2">&quot;obj_grad&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_pars</span><span class="p">,</span> <span class="n">constraint_multipliers</span><span class="p">],</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">opt_vars</span><span class="p">,</span>
                <span class="n">objective_gradient_lambda_zero</span><span class="p">,</span>
                <span class="n">constraint_jacobian</span><span class="p">,</span>
                <span class="n">hessian_lambda_zero</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;opt_vars&quot;</span><span class="p">,</span> <span class="s2">&quot;opt_pars&quot;</span><span class="p">,</span> <span class="s2">&quot;local_constraint_multipliers&quot;</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="s2">&quot;J&quot;</span><span class="p">,</span> <span class="s2">&quot;H&quot;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">matrix</span><span class="p">,</span> <span class="n">col_index</span><span class="p">,</span> <span class="n">full_grid</span><span class="p">,</span> <span class="n">var_grids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_result_format</span><span class="p">(</span><span class="n">system</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_result_map</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="s2">&quot;result_map&quot;</span><span class="p">,</span> <span class="n">mpc_inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">matrix</span><span class="p">],</span> <span class="n">mpc_input_denotations</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">make_results_view</span><span class="p">(</span><span class="n">result_matrix</span><span class="p">:</span> <span class="n">ca</span><span class="o">.</span><span class="n">DM</span><span class="p">,</span> <span class="n">stats</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Results</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Results</span><span class="p">(</span>
                <span class="n">matrix</span><span class="o">=</span><span class="n">result_matrix</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="n">col_index</span><span class="p">,</span>
                <span class="n">grid</span><span class="o">=</span><span class="n">full_grid</span><span class="p">,</span>
                <span class="n">variable_grid_indices</span><span class="o">=</span><span class="n">var_grids</span><span class="p">,</span>
                <span class="n">stats</span><span class="o">=</span><span class="n">stats</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_create_results</span> <span class="o">=</span> <span class="n">make_results_view</span></div></div>


<div class="viewcode-block" id="ALADINCollocation"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINCollocation">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ALADINCollocation</span><span class="p">(</span><span class="n">ALADINDiscretization</span><span class="p">,</span> <span class="n">DirectCollocation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Direct collocation discretization for ALADIN-based optimization.</span>

<span class="sd">    This class implements the direct collocation discretization scheme for ALADIN algorithm</span>
<span class="sd">    optimization problems. It handles discretization of continuous dynamics using</span>
<span class="sd">    collocation polynomials.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_discretize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="n">CasadiALADINSystem</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform a direct collocation discretization for ALADIN-based optimization.</span>

<span class="sd">        Args:</span>
<span class="sd">            sys: The system to be discretized</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Setup the polynomial base</span>
        <span class="n">collocation_matrices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_collocation_polynomial</span><span class="p">()</span>

        <span class="c1"># Shorthands</span>
        <span class="n">prediction_horizon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">prediction_horizon</span>
        <span class="n">timestep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">time_step</span>

        <span class="c1"># Initial State</span>
        <span class="n">initial_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="n">current_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="n">lb</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">guess</span><span class="o">=</span><span class="n">initial_state</span>
        <span class="p">)</span>
        <span class="n">previous_control</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">last_control</span><span class="p">)</span>

        <span class="c1"># Parameters that are constant over the horizon</span>
        <span class="n">model_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">)</span>
        <span class="n">control_rate_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">r_del_u</span><span class="p">)</span>
        <span class="n">aladin_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">penalty_factor</span><span class="p">)</span>

        <span class="c1"># Formulate the NLP - loop over prediction horizon</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">&lt;</span> <span class="n">prediction_horizon</span><span class="p">:</span>
            <span class="c1"># New NLP variable for the control</span>
            <span class="n">current_control</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">controls</span><span class="p">)</span>
            <span class="c1"># Penalty for control change between time steps</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span> <span class="o">+=</span> <span class="n">timestep</span> <span class="o">*</span> <span class="n">ca</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                <span class="n">control_rate_weights</span><span class="p">,</span> <span class="p">(</span><span class="n">previous_control</span> <span class="o">-</span> <span class="n">current_control</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="p">)</span>
            <span class="n">previous_control</span> <span class="o">=</span> <span class="n">current_control</span>

            <span class="c1"># New parameter for inputs</span>
            <span class="n">disturbance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">non_controlled_inputs</span><span class="p">)</span>

            <span class="c1"># Perform inner collocation loop</span>
            <span class="n">opt_vars_inside_inner</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">algebraics</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">local_couplings</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="n">opt_pars_inside_inner</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">multipliers</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="n">constant_over_inner</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">controls</span><span class="p">:</span> <span class="n">current_control</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">non_controlled_inputs</span><span class="p">:</span> <span class="n">disturbance</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">:</span> <span class="n">model_parameters</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">penalty_factor</span><span class="p">:</span> <span class="n">aladin_penalty</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">state_end</span><span class="p">,</span> <span class="n">constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_collocation_inner_loop</span><span class="p">(</span>
                <span class="n">collocation</span><span class="o">=</span><span class="n">collocation_matrices</span><span class="p">,</span>
                <span class="n">state_at_beginning</span><span class="o">=</span><span class="n">current_state</span><span class="p">,</span>
                <span class="n">states</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">states</span><span class="p">,</span>
                <span class="n">opt_vars</span><span class="o">=</span><span class="n">opt_vars_inside_inner</span><span class="p">,</span>
                <span class="n">opt_pars</span><span class="o">=</span><span class="n">opt_pars_inside_inner</span><span class="p">,</span>
                <span class="n">const</span><span class="o">=</span><span class="n">constant_over_inner</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Increment loop counter and time</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pred_time</span> <span class="o">=</span> <span class="n">timestep</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>

            <span class="c1"># New NLP variables at end of interval</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">states</span><span class="p">)</span>

            <span class="c1"># Add continuity constraint</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_constraint</span><span class="p">(</span><span class="n">next_state</span> <span class="o">-</span> <span class="n">state_end</span><span class="p">,</span> <span class="n">gap_closing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Add collocation constraints</span>
            <span class="k">for</span> <span class="n">constraint</span> <span class="ow">in</span> <span class="n">constraints</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_constraint</span><span class="p">(</span><span class="o">*</span><span class="n">constraint</span><span class="p">)</span>

            <span class="c1"># Update current state for next interval</span>
            <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>

<div class="viewcode-block" id="ALADINCollocation.initialize"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINCollocation.initialize">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system</span><span class="p">:</span> <span class="n">CasadiALADINSystem</span><span class="p">,</span> <span class="n">solver_factory</span><span class="p">:</span> <span class="n">SolverFactory</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the trajectory optimization problem, creating all symbolic</span>
<span class="sd">        variables of the OCP, the mapping function and the numerical solver.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_construct_stage_function</span><span class="p">(</span><span class="n">system</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">system</span><span class="o">=</span><span class="n">system</span><span class="p">,</span> <span class="n">solver_factory</span><span class="o">=</span><span class="n">solver_factory</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ALADINMultipleShooting"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINMultipleShooting">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ALADINMultipleShooting</span><span class="p">(</span><span class="n">ALADINDiscretization</span><span class="p">,</span> <span class="n">ADMMMultipleShooting</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiple shooting discretization for ALADIN-based optimization.</span>

<span class="sd">    This class implements the multiple shooting discretization scheme for ALADIN algorithm</span>
<span class="sd">    optimization problems. It handles discretization of continuous dynamics, addition of</span>
<span class="sd">    continuity constraints, and ALADIN-specific objective augmentation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_discretize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="n">CasadiALADINSystem</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Performs a multiple shooting discretization for ALADIN-based optimization.</span>

<span class="sd">        This method implements the multiple shooting discretization scheme for ALADIN.</span>
<span class="sd">        It handles:</span>
<span class="sd">        1. State continuity across shooting intervals</span>
<span class="sd">        2. Local coupling variables with their multipliers</span>
<span class="sd">        3. Integration of system dynamics</span>
<span class="sd">        4. Objective function construction including ALADIN terms</span>

<span class="sd">        Args:</span>
<span class="sd">            sys (CasadiALADINSystem): The system to be discretized, containing states,</span>
<span class="sd">                controls, and ALADIN-specific variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract key parameters</span>
        <span class="n">prediction_horizon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">prediction_horizon</span>
        <span class="n">timestep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">time_step</span>
        <span class="n">integration_options</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;t0&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span> <span class="n">timestep</span><span class="p">}</span>

        <span class="c1"># Initialize state trajectory</span>
        <span class="n">initial_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="n">lb</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">guess</span><span class="o">=</span><span class="n">initial_state</span>
        <span class="p">)</span>

        <span class="c1"># Initialize control input</span>
        <span class="n">previous_control</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">last_control</span><span class="p">)</span>

        <span class="c1"># Add time-invariant parameters</span>
        <span class="n">control_rate_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">r_del_u</span><span class="p">)</span>
        <span class="n">model_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">)</span>
        <span class="n">aladin_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">penalty_factor</span><span class="p">)</span>

        <span class="c1"># Create system integrator</span>
        <span class="n">dynamics_integrator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_ode</span><span class="p">(</span>
            <span class="n">sys</span><span class="p">,</span> <span class="n">integration_options</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">integrator</span>
        <span class="p">)</span>

        <span class="c1"># Perform multiple shooting discretization</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">prediction_horizon</span><span class="p">):</span>
            <span class="c1"># 1. Handle control inputs and their rate penalties</span>
            <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="n">current_control</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">controls</span><span class="p">)</span>
            <span class="n">control_rate_penalty</span> <span class="o">=</span> <span class="n">timestep</span> <span class="o">*</span> <span class="n">ca</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                <span class="n">control_rate_weights</span><span class="p">,</span> <span class="p">(</span><span class="n">previous_control</span> <span class="o">-</span> <span class="n">current_control</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span> <span class="o">+=</span> <span class="n">control_rate_penalty</span>
            <span class="n">previous_control</span> <span class="o">=</span> <span class="n">current_control</span>

            <span class="c1"># 2. Add optimization variables for current shooting interval</span>
            <span class="n">disturbance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">non_controlled_inputs</span><span class="p">)</span>
            <span class="n">algebraic_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">algebraics</span><span class="p">)</span>
            <span class="n">output_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>

            <span class="c1"># 3. Add ALADIN coupling variables and multipliers</span>
            <span class="n">local_coupling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">local_couplings</span><span class="p">)</span>
            <span class="n">multipliers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_par</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">multipliers</span><span class="p">)</span>

            <span class="c1"># 4. Construct stage-wise optimization problem</span>
            <span class="n">stage_arguments</span> <span class="o">=</span> <span class="p">{</span>
                <span class="c1"># variables</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">current_state</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">algebraics</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">algebraic_vars</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">local_couplings</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">local_coupling</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">output_vars</span><span class="p">,</span>
                <span class="c1"># parameters</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">multipliers</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">multipliers</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">controls</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">current_control</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">non_controlled_inputs</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">disturbance</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">model_parameters</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">model_parameters</span><span class="p">,</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">penalty_factor</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">aladin_penalty</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage_function</span><span class="p">(</span><span class="o">**</span><span class="n">stage_arguments</span><span class="p">)</span>

            <span class="c1"># 5. Integrate system dynamics</span>
            <span class="n">integration_result</span> <span class="o">=</span> <span class="n">dynamics_integrator</span><span class="p">(</span>
                <span class="n">x0</span><span class="o">=</span><span class="n">current_state</span><span class="p">,</span>
                <span class="n">p</span><span class="o">=</span><span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span>
                    <span class="n">current_control</span><span class="p">,</span>
                    <span class="n">local_coupling</span><span class="p">,</span>
                    <span class="n">disturbance</span><span class="p">,</span>
                    <span class="n">model_parameters</span><span class="p">,</span>
                    <span class="n">algebraic_vars</span><span class="p">,</span>
                    <span class="n">output_vars</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>

            <span class="c1"># 6. Add continuity constraints</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pred_time</span> <span class="o">=</span> <span class="n">timestep</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_opt_var</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">states</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_constraint</span><span class="p">(</span><span class="n">next_state</span> <span class="o">-</span> <span class="n">integration_result</span><span class="p">[</span><span class="s2">&quot;xf&quot;</span><span class="p">],</span> <span class="n">gap_closing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># 7. Add objective contribution from stage</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective_function</span> <span class="o">+=</span> <span class="n">stage</span><span class="p">[</span><span class="s2">&quot;cost_function&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">timestep</span>

            <span class="c1"># 8. Add model constraints</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_constraint</span><span class="p">(</span>
                <span class="n">stage</span><span class="p">[</span><span class="s2">&quot;model_constraints&quot;</span><span class="p">],</span>
                <span class="n">lb</span><span class="o">=</span><span class="n">stage</span><span class="p">[</span><span class="s2">&quot;lb_model_constraints&quot;</span><span class="p">],</span>
                <span class="n">ub</span><span class="o">=</span><span class="n">stage</span><span class="p">[</span><span class="s2">&quot;ub_model_constraints&quot;</span><span class="p">],</span>
            <span class="p">)</span>

<div class="viewcode-block" id="ALADINMultipleShooting.initialize"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINMultipleShooting.initialize">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system</span><span class="p">:</span> <span class="n">CasadiALADINSystem</span><span class="p">,</span> <span class="n">solver_factory</span><span class="p">:</span> <span class="n">SolverFactory</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the trajectory optimization problem, creating all symbolic</span>
<span class="sd">        variables of the OCP, the mapping function and the numerical solver.</span>

<span class="sd">        Args:</span>
<span class="sd">            system: The system to be discretized</span>
<span class="sd">            solver_factory: Factory to create the numerical solver</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_construct_stage_function</span><span class="p">(</span><span class="n">system</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">system</span><span class="o">=</span><span class="n">system</span><span class="p">,</span> <span class="n">solver_factory</span><span class="o">=</span><span class="n">solver_factory</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="regularize_h"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.regularize_h">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">regularize_h</span><span class="p">(</span><span class="n">hessian</span><span class="p">,</span> <span class="n">reg_param</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Regularize a Hessian matrix to ensure it is positive definite and symmetric.</span>

<span class="sd">    Args:</span>
<span class="sd">        hessian: The Hessian matrix to regularize</span>
<span class="sd">        reg_param: Regularization parameter (minimum eigenvalue)</span>

<span class="sd">    Returns:</span>
<span class="sd">        H_reg: Regularized, symmetric Hessian matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ensure matrix is symmetric before eigendecomposition</span>
    <span class="n">hessian</span> <span class="o">=</span> <span class="p">(</span><span class="n">hessian</span> <span class="o">+</span> <span class="n">hessian</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="c1"># Eigenvalue decomposition of the Hessian</span>
    <span class="n">e</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">hessian</span><span class="p">)</span>

    <span class="c1"># Take absolute value of eigenvalues</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

    <span class="c1"># Modify zero and too small eigenvalues (regularization)</span>
    <span class="n">e</span><span class="p">[</span><span class="n">e</span> <span class="o">&lt;=</span> <span class="n">reg_param</span><span class="p">]</span> <span class="o">=</span> <span class="n">reg_param</span>

    <span class="c1"># Regularization for small stepsize</span>
    <span class="n">H_reg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">V</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">@</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="c1"># Final symmetry enforcement</span>
    <span class="n">H_reg</span> <span class="o">=</span> <span class="p">(</span><span class="n">H_reg</span> <span class="o">+</span> <span class="n">H_reg</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="k">return</span> <span class="n">H_reg</span></div>


<div class="viewcode-block" id="ALADINCasadiBackendConfig"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.ALADINCasadiBackendConfig">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ALADINCasadiBackendConfig</span><span class="p">(</span><span class="n">CasadiBackendConfig</span><span class="p">):</span>
    <span class="n">discretization_options</span><span class="p">:</span> <span class="n">ALADINCasadiDiscretizationOptions</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="n">ALADINCasadiDiscretizationOptions</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="CasADiALADINBackend"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.CasADiALADINBackend">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">CasADiALADINBackend</span><span class="p">(</span><span class="n">CasADiADMMBackend</span><span class="p">):</span>
    <span class="n">discretization</span><span class="p">:</span> <span class="n">ALADINDiscretization</span>

    <span class="n">system_type</span> <span class="o">=</span> <span class="n">CasadiALADINSystem</span>
    <span class="n">discretization_types</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">DiscretizationMethod</span><span class="o">.</span><span class="n">collocation</span><span class="p">:</span> <span class="n">ALADINCollocation</span><span class="p">,</span>
        <span class="n">DiscretizationMethod</span><span class="o">.</span><span class="n">multiple_shooting</span><span class="p">:</span> <span class="n">ALADINMultipleShooting</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">config_type</span> <span class="o">=</span> <span class="n">ALADINCasadiBackendConfig</span>

<div class="viewcode-block" id="CasADiALADINBackend.get_aladin_registration"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.CasADiALADINBackend.get_aladin_registration">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_aladin_registration</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">current_vars</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">MPCVariable</span><span class="p">],</span> <span class="n">now</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
        <span class="n">mpc_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_current_mpc_inputs</span><span class="p">(</span><span class="n">agent_variables</span><span class="o">=</span><span class="n">current_vars</span><span class="p">,</span> <span class="n">now</span><span class="o">=</span><span class="n">now</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">discretization</span><span class="o">.</span><span class="n">get_aladin_registration</span><span class="p">(</span>
            <span class="n">mpc_inputs</span><span class="p">,</span> <span class="n">var_ref</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">var_ref</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="CasADiALADINBackend.shift_opt_var"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.CasADiALADINBackend.shift_opt_var">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shift_opt_var</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">discretization</span><span class="o">.</span><span class="n">shift_opt_var</span><span class="p">()</span></div>

<div class="viewcode-block" id="CasADiALADINBackend.set_global_variable"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.CasADiALADINBackend.set_global_variable">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_global_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]):</span>
        <span class="n">var_</span> <span class="o">=</span> <span class="n">ca</span><span class="o">.</span><span class="n">vertcat</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discretization</span><span class="o">.</span><span class="n">global_variable</span> <span class="o">=</span> <span class="n">var_</span></div>

<div class="viewcode-block" id="CasADiALADINBackend.get_sensitivities"><a class="viewcode-back" href="../../../../code/agentlib_mpc.optimization_backends.casadi_.html#agentlib_mpc.optimization_backends.casadi_.aladin.CasADiALADINBackend.get_sensitivities">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_sensitivities</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">AgentToCoordinator</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">aladin_datatypes</span><span class="o">.</span><span class="n">AgentToCoordinator</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">discretization</span><span class="o">.</span><span class="n">sensitivities_result</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
            <span class="n">g</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">discretization</span><span class="o">.</span><span class="n">sensitivities_result</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
            <span class="n">J</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">discretization</span><span class="o">.</span><span class="n">sensitivities_result</span><span class="p">[</span><span class="s2">&quot;J&quot;</span><span class="p">],</span>
            <span class="n">H</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">discretization</span><span class="o">.</span><span class="n">sensitivities_result</span><span class="p">[</span><span class="s2">&quot;H&quot;</span><span class="p">],</span>
        <span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, AGENT-Project Associates.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>